{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving forward, we will be using google colab to run our code. You can access google colab with this link: https://colab.research.google.com/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics and Data Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lesson we will need the following packages; pandas, matplotlib, seaborn, scipy, numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic summary statistics\n",
    "\n",
    "Basic summary statistics provide an overview of the central tendency, dispersion, and shape of a variable.\n",
    "Python's pandas library offers a convenient method called `describe()` to generate summary statistics for a DataFrame.\n",
    "\n",
    "In this example, we import the pandas library and load the data from a CSV file into a DataFrame named data. The `describe()`\n",
    "method is then called on the DataFrame to calculate summary statistics such as count, mean, standard deviation, minimum, quartiles,\n",
    "and maximum for each numerical column in the data. The result is stored in the summary variable and printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "df_students = pd.read_csv('students_performance.csv')\n",
    "\n",
    "# Generate summary statistics\n",
    "summary = df_students.describe()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative vs Quantitative data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be either qualitative or quantitative.\n",
    "\n",
    "Qualitative data refers to data that can be usually divided into groups. For example, data about marriage status can be sorted by unmarried, married, or engaged. They can also be divided into categories that have no order(nominal variables) such as the marriage example or categories that can be ordered(ordinal) such as a person's generation(Ex: Gen z, Millenial, etc...). \n",
    "\n",
    "Quantitative data are numerical variables, representing data that can be measured or counted and are typically expressed as numbers. Examples could be the weight of a bar, the number of people who finished a race, etc... Quantitative data can be separated further into discrete and continuous variables. Discrete variables are often found from counting and are usually finite. Examples could be how many siblings you have, the cars someone sells in a month, etc... Continuous variables can take on any value and can be fractional or decimal values. Examples could be height, age, and temperature."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style =\"background-color:yellow\">\n",
    "TODO: Print out the statistical summary for your data set and interpret what the values represent to your classmates. Please write down which columns are qualitative and which ones are quantitative.\n",
    "</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Missing Values and Identifying Outliers\n",
    "\n",
    "Missing values and outliers are important considerations in data analysis. Python's pandas library provides functions to count missing values and identify outliers.\n",
    "\n",
    "To count missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values in each column\n",
    "missing_values = df_students.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `isnull()` function checks each element in the DataFrame and returns `True` if it is missing `(NaN)` and `False` otherwise. By calling `sum()` on the result, we obtain the count of missing values for each column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are some missing values detected let's explore how to clean our data. For quantitative data, you might fill in the average for a column. For example, let's populate the missing math and reading scores with the average values for those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the average of a math score\n",
    "math_average = df_students['math score'].mean()\n",
    "\n",
    "# Fill empty cells with the average\n",
    "df_students['math score'].fillna(math_average, inplace=True)\n",
    "\n",
    "# Find the average of a column\n",
    "reading_score = df_students['reading score'].mean()\n",
    "\n",
    "# Fill empty cells with the average\n",
    "df_students['reading score'].fillna(reading_score, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if our data is categorical/qualitative? Let's fill those values with the most frequent response or the 'mode', and apply that to the lunch column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mode for the specific column\n",
    "lunch_mode = df_students['lunch'].mode()[0]\n",
    "\n",
    "print(f\"This is the most common lunch '{lunch_mode}'\")\n",
    "\n",
    "# Fill missing values in the specific column with the mode\n",
    "df_students['lunch'].fillna(lunch_mode, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check back in to see if we filled in some of those missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values in each column\n",
    "missing_values = df_students.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal & Bimodal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe frequencies and relative frequencies of data in our dataframe. It can be helpful to contextualize the type of data we have and the different categories it can be split up into. Furthermore, it can help us choose the best way to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_students['lunch']  # Example data\n",
    "\n",
    "frequency_table = {}\n",
    "\n",
    "for value in data:\n",
    "    if value in frequency_table:\n",
    "        frequency_table[value] += 1\n",
    "    else:\n",
    "        frequency_table[value] = 1\n",
    "\n",
    "print(f\"Frequency table: {frequency_table}\")\n",
    "\n",
    "\n",
    "data = df_students['lunch']  # Example data\n",
    "\n",
    "relative_frequency_table = {}\n",
    "\n",
    "total_values = len(data)\n",
    "\n",
    "for value in data:\n",
    "    if value in relative_frequency_table:\n",
    "        relative_frequency_table[value] += 1 / total_values\n",
    "    else:\n",
    "        relative_frequency_table[value] = 1 / total_values\n",
    "\n",
    "print(f\"Relative frequency table: {relative_frequency_table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore what a normal distribution looks like using a histogram. A histogram allows us to view categorical data continuously, which will give a visual representation of our frequency data from the prior cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we generate 1000 random samples from a normal distribution with a mean of 0 and a standard deviation of 1 using `np.random.normal()`. The generated samples are then plotted as a histogram using\n",
    "`plt.hist()`. The bins parameter specifies the number of bins for the histogram, `density=True` ensures that the histogram is normalized, alpha controls the transparency of the bars, and color sets the color of the bars to blue.\n",
    "\n",
    "Finally, the code sets the x-axis label to `\"Value\"`, the y-axis label to `\"Probability Density\"`, and the title of the plot to `\"Normal Distribution\"` using `plt.xlabel(), plt.ylabel()`, and `plt.title()` respectively.\n",
    "\n",
    "The `linspace()` function is for generating a red line showing the probability density function. \n",
    "\n",
    "Running this code will display a plot with a histogram representing the generated random samples from the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the parameters for the normal distribution\n",
    "mean = 0\n",
    "std_dev = 1\n",
    "\n",
    "# Generate random samples from a normal distribution\n",
    "samples = np.random.normal(mean, std_dev, 1000)\n",
    "\n",
    "# Plot the histogram of the samples\n",
    "plt.hist(samples, bins=30, density=True, alpha=0.7, color='blue')\n",
    "\n",
    "x = np.linspace(-5, 5, 100)\n",
    "pdf = (1 / (std_dev * np.sqrt(2 * np.pi))) * np.exp(-(x - mean)**2 / (2 * std_dev**2))\n",
    "plt.plot(x, pdf, color='red', linewidth=2)\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Normal Distribution')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create an example of bimodal data, we can generate random samples from a mixture of two Gaussian(bell-shaped) distributions. Here's the modified code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random samples from a mixture of two Gaussian distributions\n",
    "mean1 = -2\n",
    "std_dev1 = 1\n",
    "samples1 = np.random.normal(mean1, std_dev1, 500)\n",
    "\n",
    "mean2 = 2\n",
    "std_dev2 = 0.5\n",
    "samples2 = np.random.normal(mean2, std_dev2, 500)\n",
    "\n",
    "samples = np.concatenate((samples1, samples2))\n",
    "\n",
    "# Plot the histogram of the samples\n",
    "plt.hist(samples, bins=30, density=True, alpha=0.7, color='blue')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Bimodal Data Example')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution curves are how a data set looks when plotted on a graph. Distributions can be skewed to the right or the left or a various number of shapes. In the example below a histogram with 100 separate random samples from a normal distribution are taken and then plotted on a histogram.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skews\n",
    "\n",
    "Understanding the distribution of variables helps in assessing their shape, skewness, and potential data transformations. Python offers several visualization libraries to examine variable distributions. Let's use Matplotlib to create a histogram and Seaborn to generate a box plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of a variable\n",
    "plt.hist(df_students['math score'], bins=20)\n",
    "\n",
    "# We use the .xlabel() function to give the x-axis a label\n",
    "plt.xlabel('Variable')\n",
    "\n",
    "# We use the .ylabel() function to give the y-axis a label\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# We use the .title() function to give the histogram a title\n",
    "plt.title('Histogram of Variable')\n",
    "\n",
    "#displays the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This slightly left-skewed data should have a mean that is pulled down by its outliers. Let's verify that the mean is smaller than the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_median = df_students['reading score'].median()\n",
    "print(F\"The median reading score is: {reading_median}\")\n",
    "df_students['reading score'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the skew was quite small, you can see that the mean is only a bit smaller than the median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Deviation/Statistic calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning about where the statistic calculations come from is important to understand how they correlate with each other\n",
    "and what their significance is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example below we are taking the mean math score by using the `.mean()` function. Using this we calculate the variance of the data for the math scores. To calculate variance we take the residual of each data point and square it. We can use the `.std()` function to find the standard deviation for each data point. \n",
    "\n",
    "To find the z-score, a measure of how many standard deviations a data point is from the mean. we have to take the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'math score' is a column in your DataFrame\n",
    "# Calculate mean math score\n",
    "mean_math_score = df_students['math score'].mean()\n",
    "\n",
    "# Create a new column 'mathscorevariance' representing the variance of each math score from the mean. The\n",
    "# variance is the square of the difference between a value and the mean for that value.\n",
    "df_students['math_score_variance'] = (df_students['math score'] - mean_math_score)**2\n",
    "\n",
    "# Calculate standard deviation of all the math scores. This is done by summing all of the squares from\n",
    "# above, then dividing them by either the # of records (N) for an entire population, the number of\n",
    "# records minus 1 (N-1) if you only have a sample.\n",
    "std_math_score = df_students['math score'].std()\n",
    "\n",
    "# Create a new column 'math_score_std_dev' representing the standard deviation of each math score from the\n",
    "# mean. This is often called a Z-Score. Knowing the zscore for a record helps inform us how far\n",
    "# a value is from the mean.\n",
    "df_students['math_score_std_dev'] = (df_students['math score'] - mean_math_score) / std_math_score\n",
    "\n",
    "df_students[['math_score_std_dev', 'math score', 'math_score_variance']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is normally the case for programming, there is a module that can calculate things much more easily for you. Here we will use the scipy package to calculate the z score in a single line of code, then cross-reference the results with our above dataframe data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate z-scores for each value in a column. The nan_policy argument to this function will omit any null (or \"non-number\") values in this column.\n",
    "df_students['math_score_std_dev'] = stats.zscore(df_students['math score'], nan_policy='omit')\n",
    "\n",
    "df_students[['math_score_std_dev']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Categorical Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a bar plot using the Seaborn library in Python. The `sns.barplot()` function takes three arguments:\n",
    "\n",
    "- x: The column name of the categorical variable to be plotted on the x-axis.\n",
    "- y: The column name of the continuous variable to be plotted on the y-axis.\n",
    "- data: The name of the DataFrame that contains the data to be plotted.\n",
    "\n",
    "In this case, the x argument is set to \"lunch\", which is a categorical variable that represents whether a student receives free/reduced lunch or not. The y argument is set to \"math score\", which is a continuous variable that represents a studentâ€™s math score. Finally, the data argument is set to `df_students`, which is the name of the DataFrame that contains the data.\n",
    "\n",
    "The resulting plot will show the average math score for students who receive free/reduced lunch and those who do not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot\n",
    "sns.barplot(x=\"lunch\", y=\"math score\", data=df_students)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side-by-Side Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "categories = ['math score', 'reading score']\n",
    "values1 = df_students['math score'].mean()\n",
    "values2 = df_students['reading score'].mean()\n",
    "\n",
    "# Set the positions of the bars on the x-axis\n",
    "bar_width = 0.35\n",
    "bar_positions1 = np.arange(len(categories))\n",
    "bar_positions2 = bar_positions1 + bar_width\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the bars for the first set of values\n",
    "ax.bar(bar_positions1, values1, width=bar_width, label='Set 1')\n",
    "\n",
    "# Plot the bars for the second set of values\n",
    "ax.bar(bar_positions2, values2, width=bar_width, label='Set 2')\n",
    "\n",
    "\n",
    "# Add labels, title, and legend\n",
    "ax.set_xlabel('Scores')\n",
    "ax.set_ylabel('Values')\n",
    "ax.set_title('Side-by-Side Bar Chart')\n",
    "ax.set_xticks(bar_positions1 + bar_width / 2)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend()\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pie Chart"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a pie chart using the Matplotlib library in Python. The `value_counts()` function is used to count the number of occurrences of each unique value in the \"race/ethnicity\" column of the DataFrame `df_students`. The resulting counts are stored in the `category_counts` variable.\n",
    "\n",
    "The `plt.pie()` function takes three arguments:\n",
    "\n",
    "- x: The values to be plotted. In this case, it is the values of `category_counts`.\n",
    "- labels: The labels for each value. In this case, it is the index of `category_counts`.\n",
    "- autopct: A string or function used to format the percentage values.\n",
    "\n",
    "The resulting pie chart will show the distribution of race/ethnicity in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pie chart\n",
    "category_counts = df_students['race/ethnicity'].value_counts()\n",
    "plt.pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%')\n",
    "plt.title('Distribution of Race/Ethnicity')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Quantitative Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box-Whisker plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we utilize `sns.boxplot()` from the seaborn library to create a box plot of the variable in the DataFrame data. The x parameter is set to the column of interest. Similarly, `xlabel()` and `title()` are used to label the x-axis and provide a title to the plot. Finally, `plt.show()` displays the box plot. The points towards the left of the graph can be categorized as outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a box plot of a variable\n",
    "sns.boxplot(x=df_students['math score'])\n",
    "plt.xlabel = ('Variable')\n",
    "plt.title('Box Plot of Variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatterplot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sns.scatterplot()` function takes three arguments:\n",
    "\n",
    "- data: The name of the DataFrame that contains the data to be plotted.\n",
    "- x: The column name of the variable to be plotted on the x-axis.\n",
    "- y: The column name of the variable to be plotted on the y-axis.\n",
    "\n",
    "In this case, the data argument is set to `df_students`, which is the name of the DataFrame that contains the data. The x argument is set to `\"math score\"`, which is a variable that represents the persons math score. The y argument is set to `\"reading score\"`, which is another variable that represents the persons reading score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv data\n",
    "sns.scatterplot(data = df_students, x = \"math score\", y = \"reading score\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style =\"background-color:yellow\">\n",
    "TODO - Using any of the above-mentioned graphs spend the next 5 minutes collecting, aggregating, and sorting your data. Then gather the necessary inputs and create a graph most useful for a reader trying to interpret your data. Afterwards, have a 5 minutes discussion going over every step of the process with another student\n",
    "<span\\>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
