{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes and data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Steps\n",
    "\n",
    "Open up Colab and create a new notebook. This will be your workspace for this lesson. Remember to refresh yourself with Colab with the video in the `README.md`. Once completed you will be able to install all the nessessary packages. For this lesson you will need only pandas.\n",
    "\n",
    "To follow along make sure to download the `pokemon_data.csv` located in the github. Once that is complete add that to your Colab workspace by importing the file. This is done by clicking the files button on the left side of the screen and then pressing on 'Upload to session storage'. \n",
    "\n",
    "While going through the lesson feel free to copy each block of code from the github and paste into the Colab terminal.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data into Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure in your colab files the name of your csv file is  `pokemon_data.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read csv data\n",
    "df = pd.read_csv('pokemon_data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas can easily read from different file formats. Here are some examples of what it looks like to read from other files. Don't run this code as the files are not defined - it will throw you an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of reading excel data\n",
    "# df_xlsx = pd.read_excel('pokemon_data.xlsx')\n",
    "# df_xlsx.head()\n",
    "\n",
    "# Example of reading txt data\n",
    "# df_txt = pd.read_csv('pokemon_data.txt', delimiter='\\t')\n",
    "# df_txt.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Data in Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you will some sample rows from your dataset using the `.head()` function. Read the first 5 rows by default, if you want a different number of rows pass it as an argument to the head function like `df.head(10)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding your data with pandas can start out in a couple ways. First we can find out the different columns in the dataframe using the `.columns()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read headers\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take all the code from the above cells and put them into your own file called `main.py` in your repl. Then, create a new csv file for the data you've chosen to work with, then copy all the data into that csv file. Be sure to substitute the name of the csv file from the above code `(pokemon_data.csv)` with your own data's csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read slices of data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select certain columns and display all the row values associated with them by calling the dataframe and in square brackets inserting the names of columns you want the row data called for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read these columns from all rows\n",
    "print(df[['Name', 'Type 1', 'HP']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style =\"background-color:yellow\">\n",
    "TODO: Find 2 columns and show all the values in those columns.\n",
    "</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To return the first 4 rows we would use the `.iloc[]` function in order to retrieve that data with a specific slice inserted within the square brackets. `df.iloc[0:4]`, retrieves the first 4 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[0]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The for loop allows us to access every row and for every row in our data set we are printing the string \"new row\". Then we are printing the index followed by the data that is associated with the row and this would all be ordered by the pokemon name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read every row\n",
    "for index, row in df.iterrows():\n",
    "    print(\"\\nNew Row\")\n",
    "    print(index, row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.iloc[]` function is important for returning specific values using their location. By changing the inputs and the amount of inputs you will be able to return entire rows of data or singular cells. Below are 4 examples of using the `.iloc[]` function returning different outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a specific row's column (row 10 column 2 value)\n",
    "print(df.iloc[10, 2])\n",
    "\n",
    "# Read a range of rows\n",
    "print(df.iloc[1:5])\n",
    "\n",
    "# Read specific column from a range of rows\n",
    "print(df.iloc[1:5, 1])\n",
    "\n",
    "# Read range of columns from a range of rows\n",
    "print(df.iloc[1:5, 1:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style =\"background-color:yellow\">\n",
    "TODO: Using the .iloc[] choose 5 rows you want displayed and describe to a classmate in a couple sentences how one could use the output to help understand the data better.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section starts with the `.value_counts()` function where it aggregates data to make it easier to read. In the below cell, we want to find out the amount of pokemon in the dataset that belongs to each generation. We start out by specifying what dataframe we want to use and then input the column we are aggregating by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a count for each unique value in the 'Generation' column\n",
    "df.Generation.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style =\"background-color:yellow\">\n",
    "TODO: Describe how the .value_counts() function could be used to aggregate data in your dataset in a useful way. Then aggregate the data using that function and see if it worked in the way it was intended to. \n",
    "</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we want to find out how many pokemon are considered legendary we can use `.sum()` after specifying the column we want to aggregate by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of pokemon that are considered legendary.\n",
    "Legendary = df['Legendary'].sum()\n",
    "print(f\"Pokemon that are considered legendary: {Legendary}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the total pokemon we can use the number of unique 'IDs' there are in the ID column which in this case is declared using a pound sign. Then we use the `.count()` function since we want to find the total count of IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total number of respondents using the count of 'ID' column (assuming each ID is unique).\n",
    "total_pokemon = df['#'].count()\n",
    "print(f\"Total pokemon: {total_pokemon}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting/Describing Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting and describing data is important to figure out what the data looks like with certain filters applied. Below is an example of sorting pokemon by their type alphabetically and the amount of HP they have. First pokemon are ordered alphabetically by 'Type 1' (ex: Ghost before Water). Then pokemon are ordered numerically by 'HP' (ex: 35 before 60)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by type and health points (HP) so type is alphabetical ascending and \n",
    "# hp is numeric ascending. Ascending is either true or false.\n",
    "\n",
    "df.sort_values(by=['Type 1', 'HP'],ascending = False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style =\"background-color:yellow\">\n",
    "TODO: List the 3 best columns that could be used to sort the values in a useful way. Provide a one sentence explanantion on why these columns would help someone interpret the data better. Lastly, use the .sort_values() function to sort the data in the desired way.\n",
    "</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.groupby()` function is a powerful tool that allows data to be sorted and aggregated in whatever way you choose. In the case below the pokemon types are used in order to group the pokemon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'Type 1' and count the values of 'Type 2' in each group.\n",
    "df.groupby('Type 1')[['Type 2','Legendary']].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making changes to the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting new columns and dropping columns based on present data is important for reading code as it can provide more information to the user and allows more ways for data sorting. In this case a column called 'Total' is made using various other columns by adding up the values of other columns. All the columns must by in a numberic data type in order for this to work. Another column, 'Sp. Power', is made and then dropped by using the `.drop()` function and then specifying which column should be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in each row based on a calculation that would be performed on every row\n",
    "df['Total'] = df['HP'] + df['Attack'] + df['Defense'] + df['Sp. Atk'] + df['Sp. Def'] + df['Speed']\n",
    "\n",
    "# Checkout the new column\n",
    "df.head()\n",
    "\n",
    "# Create a new column again\n",
    "df['Sp. Power'] = df['Sp. Atk'] + df['Sp. Def']\n",
    "\n",
    "# Drop the newly created column\n",
    "df = df.drop(columns=['Sp. Power'])\n",
    "\n",
    "# The column should be gone now\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style =\"background-color:yellow\">\n",
    "TODO: Make 2 columns that would be beneficial to interpreting the data. Provide a sentence explanantion on what is useful about the information provided by these new columns. Afterwards drop 1 of the columns and provide an explanation on why the remaining added column was better to leave in. \n",
    "</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving our Data (Exporting into Desired Format)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we described the earlier in the lesson, pandas can easily read from other file formats and read data. However, it can also __export__ to these different formats just as easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('modified.csv', index=False)\n",
    "\n",
    "# df.to_excel('modified.xlsx', index=False)\n",
    "\n",
    "# df.to_csv('modified.txt', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering data involves finding what is nessessary, manipulating it to showcase it in an easy to read way and often saving it. Below the `.loc()` function is used to find what data is wanted. Then that filtered data is assigned to a new dataframe. By using the `.reset_index()` function we can use the original index and use it as a column in our new `'filtered.csv'` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that in dataframes there is no \"and\", only &. Lets filter for some data.\n",
    "new_df = df.loc[(df['Type 1'] == 'Grass') & (df['Type 2'] == 'Poison') & (df['HP'] > 70) & (df['Attack'] > 50)]\n",
    "\n",
    "# Reassign the row numbers\n",
    "new_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(new_df.head())\n",
    "\n",
    "# Save this filtered data to a new csv\n",
    "new_df.to_csv('filtered.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Conditional Changes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we want to change values based on conditions. Below if a Legendary pokemon is found they will be labeled with 'Test 2' instead of 'TRUE'. Then we display the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Conditionally change a column\n",
    "df.loc[df['Total'] > 500, ['Generation']] = ['Special']\n",
    "\n",
    "# Display the column\n",
    "df['Generation']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Statistics (Groupby)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregating statistics using `.groupby()` involves creating a new column known as count with an assigned value of 1. Then we populate this column using the \n",
    "`.groupby()` function and inputing how the data should be grouped. The assigned value in the 'count' column is changed to whatever count is produced using the `.groupby` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column with every value initialized to 1\n",
    "df['count'] = 0\n",
    "\n",
    "# Group and display a column's count based on number of Type 1 and Type 2 pokemon\n",
    "df.groupby(['Type 1', 'Type 2']).count()['count']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style =\"background-color:yellow\">\n",
    "TODO: Using the .groupby() and the .count() functions determine what columns could be best aggregated in a similar method as the cell above. Remember you must create a new column to aggregate that data in.\n",
    "</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with large amounts of data\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes sorting through all the data is too much, so chunking the data is very helpful in order to make easier to read. There are many ways to chunk data but in this case the data is chunked by type and represented as a count. There are other ways to chunk such as using location, columns names, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new2_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "# Chunk a dataframe from a csv\n",
    "for dfr in pd.read_csv('pokemon_data.csv', chunksize=5):\n",
    "    results = dfr.groupby(['Type 1']).count()\n",
    "    new2_df = pd.concat([new2_df, results])\n",
    "new2_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c0a86e4f8890231894208390584190121cc22b291bf83a826b39466a0a94c90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
