{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving forward, we will be using google colab to run our code. You can access google colab with this link: \n",
    "https://www.bing.com/ck/a?!&&p=27045da591c34ac2JmltdHM9MTY4OTM3OTIwMCZpZ3VpZD0xZTEwMzZkMS04MzQ1LTYwZTAtMWYwZi0yNjFkODI2YzYxODQmaW5zaWQ9NTE5MA&ptn=3&hsh=3&fclid=1e1036d1-8345-60e0-1f0f-261d826c6184&psq=google+colaboratory&u=a1aHR0cHM6Ly9jb2xhYi5yZXNlYXJjaC5nb29nbGUuY29tLw&ntb=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation and Relationship Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation and relationship analysis are important techniques in data science for understanding the association between variables. In this lesson, we will explore the concept of correlation, its types, and how to analyze relationships between variables using Python. We will use practical examples to demonstrate these concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation measures the statistical relationship between two variables. It helps us understand how changes in one variable are associated with changes in another variable. Correlation does not imply causation, but it indicates the strength and direction of the relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different correlation coefficients used to quantify the relationship between variables:\n",
    "\n",
    "Pearson correlation coefficient (r): It measures the linear relationship between two continuous variables. The value of r ranges from -1 to +1. A positive value indicates a positive linear relationship, a negative value indicates a negative linear relationship, and a value close to zero indicates no linear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([3, 4, 5, 6, 7])\n",
    "\n",
    "# Calculate Pearson correlation coefficient\n",
    "correlation_matrix = np.corrcoef(x, y)\n",
    "\n",
    "# since .corrcoef returns a matrix of the correlations\n",
    "# for different combinations of variables, we choose the index\n",
    "# [0, 1] to access the correlation for variable 1 (0th index) \n",
    "# and variable 2 (1st index)\n",
    "pearson_coefficient = correlation_matrix[0, 1]\n",
    "\n",
    "print(\"Pearson correlation coefficient:\", correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = \"background-color: yellow\">\n",
    "TODO: Choose 2 numerical variables that you would like to analyze the relationship between. Using our pokemon example, a good choice could be HP and Attack. After choosing the variables, find the correlation coefficient for the 2 variables. Then, explain what your resulting coefficient means to your classmates.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize our correlation by seeing the scatterplot of the variables plotted against one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([3, 4, 5, 6, 7])\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Scatter Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When interpreting correlation coefficients, consider the following:\n",
    "\n",
    "Positive Correlation: A positive correlation coefficient indicates that as one variable increases, the other variable tends to increase as well. The closer the value is to +1, the stronger the positive correlation.\n",
    "\n",
    "Negative Correlation: A negative correlation coefficient indicates that as one variable increases, the other variable tends to decrease. The closer the value is to -1, the stronger the negative correlation.\n",
    "\n",
    "No Correlation: A correlation coefficient close to zero indicates no linear relationship between the variables. However, it's important to note that there could still be a non-linear relationship or a relationship that is not captured by the correlation coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation analysis may be affected by missing values and outliers in the data. It's crucial to handle them appropriately:\n",
    "\n",
    "Missing Values: Missing data can lead to biased correlation results. You can handle missing values by imputation techniques (e.g., mean, median, or regression imputation) or by removing observations with missing data, depending on the situation.\n",
    "\n",
    "Outliers: Outliers can have a significant impact on correlation coefficients. Consider identifying and handling outliers before performing correlation analysis. Techniques like winsorization, trimming, or using robust correlation measures can help mitigate the influence of outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next few lessons, we will be diving into machine learning. Machine learning is a branch of artificial intelligence (AI) that focuses on developing algorithms and models that enable computers to learn and make predictions or decisions without being explicitly programmed. In simple terms, machine learning is about teaching computers how to learn from data and use that knowledge to perform tasks or make predictions.\n",
    "\n",
    "The 3 fundamental steps of Machine Learning can be described as first getting your data, then creating a model and fitting it to the existing data, and lastly using the model to make predictions based off of how it is fitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn, also known as sklearn, is a widely-used open-source machine learning library for Python. It provides a range of efficient tools and algorithms for various machine learning tasks, including classification, regression, clustering, dimensionality reduction, model selection, and preprocessing of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to load our data set. Sklearn does have its own pre-loaded datasets that we can access. Since all of our datasets come from a source outside sklearn, we access our dataset using pandas like we have done in the past. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load a dataset from a CSV file using Pandas\n",
    "data = pd.read_csv('StudentsPerformance.csv')\n",
    "data.columns\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now before we do any actual Machine Learning, we need to prep our data. Machine Learning at heart is using Statistical methods to predict an outcome. We cannot predict anything if our variables are all categorical. Alot of your data sets use Categorical Variables (an example in our StudentsPerformance dataset would be the gender column having a string stating whether someone is female or male) for various columns. One way we can convert these into Quantitative Variables is by using the OneHotEncoder class inside of sklearn. It looks for all the unique values in a column and converts them into respective values. Using our student example, it may convert male to 0 and female to 1. \n",
    "\n",
    "Here's how you would use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create an instance of the OneHotEncoder and fit_transform the data\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# store our new data in a variable\n",
    "quantitative_data = encoder.fit_transform(data[['gender']])\n",
    "\n",
    "# Print the transformed data as an array\n",
    "print(quantitative_data.toarray())\n",
    "\n",
    "# Print the encoded feature names\n",
    "print(encoder.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = \"background-color: yellow\">\n",
    "TODO: Now that we know how to transform Categorical Variables into Quantitative Variables, think about a column you may want to predict and what column or columns you may want to use as your features. Then, if those selected feature columns are not already quantitative variables, convert them.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split our data into features and the column we are trying to predict. X would be our column(s) that we use as features and y would be the column we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load a dataset from a CSV file using Pandas\n",
    "data = pd.read_csv('StudentsPerformance.csv')\n",
    "\n",
    "X = data.iloc[:, :-1].values  # Features\n",
    "# [:, :-1] specifies that we want to select all rows (:) and all columns except the last one (:-1).\n",
    "\n",
    "y = data.iloc[:, -1].values  # Target variable\n",
    "# [:, -1] specifies that we want to select all rows (:) and only the last column (-1).\n",
    "\n",
    "# if we want specific columns, we could replace the -1 with a different index or with brackets around the column names\n",
    "\n",
    "# .values converts the selected data into a NumPy array.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For today, we will be learning about the K-Nearest Neighbors Classifier. The K-Nearest Neighbors (KNN) classifier is a simple and intuitive algorithm for classification tasks. It works based on the idea that similar data points tend to belong to the same class.Imagine you have a dataset with labeled examples of different objects, such as fruits, where each object has certain features like color, shape, and size. The KNN classifier aims to classify new, unlabeled objects based on their similarity to the labeled objects.\n",
    "\n",
    "If we were to look at this from a graphical perspective using our students example, imagine we have a scatterplot with our level of education(X) plotted against math score(y). We have a point with a level of eduction of 'bachelors' that we want to predict the math score of. The KNN Classifier would choose k-points that are closest to this point on the scatterplot and take the average math score of these points to estimate the predicted point's math score.\n",
    "\n",
    "How KNN Works:\n",
    "\n",
    "Step 1: Select a value for k, which represents the number of nearest neighbors to consider.\n",
    "Step 2: Given a new, unlabeled object, find the k nearest neighbors to that object in the feature space.\n",
    "Step 3: Determine the majority class among the k neighbors.\n",
    "Step 4: Assign the majority class as the predicted class for the new object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how KNN works, we have to split our dataset into training and testing data. Think of training data as the material used to teach a model. It consists of examples or observations with known input values and corresponding output labels or target values. The training data is used to build or train the model. The model learns patterns, relationships, and rules from the training data, enabling it to make predictions or decisions.Testing data is used to assess how well the trained model generalizes to unseen or new data. It serves as a benchmark to evaluate the model's performance and measure its ability to make accurate predictions on data it hasn't encountered during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# here we are splitting our data into training and testing datasets\n",
    "# the test_size parameter allows us to change what percent of our data we want to designate for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the KNeighborsClassifier with k=3 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = \"background-color: yellow\">\n",
    "TODO: Using the knowledge we have about KNN, create a model to predict the values of your column of choice. \n",
    "</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
